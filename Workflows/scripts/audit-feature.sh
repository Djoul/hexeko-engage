#!/bin/bash

# Script d'Audit Automatique - MÃ©thodologie Backend API
# Usage: ./workflows/scripts/audit-feature.sh [FEATURE_ID] [TYPE] [OPTIONS]

set -e

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/../.." && pwd)"
AUDIT_REPORTS_DIR="${PROJECT_ROOT}/audit-reports"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Functions
log() {
    echo -e "${BLUE}[AUDIT]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

show_help() {
    cat << EOF
ðŸ” Script d'Audit Automatique - MÃ©thodologie Backend API

USAGE:
    ./workflows/scripts/audit-feature.sh [FEATURE_ID] [TYPE] [OPTIONS]

ARGUMENTS:
    FEATURE_ID    Identifiant de la fonctionnalitÃ© (UE-XXX, namespace, commit)
    TYPE          Type d'audit: full|architecture|tests|performance|documentation

OPTIONS:
    --jira        RÃ©cupÃ©rer depuis Jira (par dÃ©faut si UE-XXX)
    --namespace   Auditer un namespace complet (ex: app/Integrations/Vouchers/Amilon)
    --commit      Auditer un commit spÃ©cifique
    --pr          Auditer une Pull Request
    --output-dir  Dossier de sortie (dÃ©faut: ./audit-reports)
    --format      Format de sortie: html|markdown|json (dÃ©faut: markdown)
    --no-tests    Skip les tests automatisÃ©s
    --help, -h    Afficher cette aide

EXEMPLES:
    # Audit complet d'une story Jira
    ./workflows/scripts/audit-feature.sh UE-268 full

    # Audit architecture d'un module
    ./workflows/scripts/audit-feature.sh app/Integrations/Vouchers/Amilon architecture --namespace

    # Audit performance d'une API
    ./workflows/scripts/audit-feature.sh UE-301 performance

    # Audit d'un commit
    ./workflows/scripts/audit-feature.sh abc123 full --commit

    # Audit interactif
    ./workflows/scripts/audit-feature.sh --interactive

EOF
}

# Parse arguments
FEATURE_ID=""
AUDIT_TYPE="full"
SOURCE_TYPE=""
OUTPUT_DIR="${AUDIT_REPORTS_DIR}"
OUTPUT_FORMAT="markdown"
RUN_TESTS=true
INTERACTIVE=false

while [[ $# -gt 0 ]]; do
    case $1 in
        --help|-h)
            show_help
            exit 0
            ;;
        --jira)
            SOURCE_TYPE="jira"
            shift
            ;;
        --namespace)
            SOURCE_TYPE="namespace"
            shift
            ;;
        --commit)
            SOURCE_TYPE="commit"
            shift
            ;;
        --pr)
            SOURCE_TYPE="pr"
            shift
            ;;
        --output-dir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --format)
            OUTPUT_FORMAT="$2"
            shift 2
            ;;
        --no-tests)
            RUN_TESTS=false
            shift
            ;;
        --interactive)
            INTERACTIVE=true
            shift
            ;;
        -*)
            error "Option inconnue: $1"
            show_help
            exit 1
            ;;
        *)
            if [[ -z "$FEATURE_ID" ]]; then
                FEATURE_ID="$1"
            elif [[ -z "$AUDIT_TYPE" ]]; then
                AUDIT_TYPE="$1"
            fi
            shift
            ;;
    esac
done

# Mode interactif
if [[ "$INTERACTIVE" == "true" ]]; then
    log "ðŸŽ¯ Mode interactif activÃ©"

    echo "Quel type d'audit souhaitez-vous effectuer ?"
    echo "1) Story/Epic Jira (UE-XXX)"
    echo "2) Module/Namespace"
    echo "3) Commit spÃ©cifique"
    echo "4) Pull Request"
    read -p "Choix (1-4): " choice

    case $choice in
        1)
            SOURCE_TYPE="jira"
            read -p "ID Jira (ex: UE-268): " FEATURE_ID
            ;;
        2)
            SOURCE_TYPE="namespace"
            read -p "Namespace (ex: app/Integrations/Vouchers/Amilon): " FEATURE_ID
            ;;
        3)
            SOURCE_TYPE="commit"
            read -p "Commit hash: " FEATURE_ID
            ;;
        4)
            SOURCE_TYPE="pr"
            read -p "PR number: " FEATURE_ID
            ;;
        *)
            error "Choix invalide"
            exit 1
            ;;
    esac

    echo "Type d'audit :"
    echo "1) Complet (full)"
    echo "2) Architecture uniquement"
    echo "3) Tests et coverage"
    echo "4) Performance"
    echo "5) Documentation"
    read -p "Choix (1-5): " audit_choice

    case $audit_choice in
        1) AUDIT_TYPE="full" ;;
        2) AUDIT_TYPE="architecture" ;;
        3) AUDIT_TYPE="tests" ;;
        4) AUDIT_TYPE="performance" ;;
        5) AUDIT_TYPE="documentation" ;;
        *) AUDIT_TYPE="full" ;;
    esac
fi

# Validation des arguments
if [[ -z "$FEATURE_ID" ]]; then
    error "Feature ID requis"
    show_help
    exit 1
fi

# Auto-dÃ©tection du type de source
if [[ -z "$SOURCE_TYPE" ]]; then
    if [[ "$FEATURE_ID" =~ ^UE-[0-9]+$ ]]; then
        SOURCE_TYPE="jira"
        log "Auto-dÃ©tection: Source Jira"
    elif [[ "$FEATURE_ID" =~ ^[a-f0-9]{6,40}$ ]]; then
        SOURCE_TYPE="commit"
        log "Auto-dÃ©tection: Commit hash"
    elif [[ "$FEATURE_ID" =~ ^[0-9]+$ ]]; then
        SOURCE_TYPE="pr"
        log "Auto-dÃ©tection: Pull Request"
    elif [[ "$FEATURE_ID" == *"/"* ]]; then
        SOURCE_TYPE="namespace"
        log "Auto-dÃ©tection: Namespace"
    else
        warning "Type de source non dÃ©tectÃ©, utilisation de 'jira' par dÃ©faut"
        SOURCE_TYPE="jira"
    fi
fi

# CrÃ©ation du dossier de rapport
mkdir -p "$OUTPUT_DIR"
REPORT_FILE="${OUTPUT_DIR}/audit-${FEATURE_ID//\//-}-${AUDIT_TYPE}-${TIMESTAMP}.${OUTPUT_FORMAT}"

log "ðŸ” DÃ©marrage audit de ${FEATURE_ID}"
log "ðŸ“ Type: ${AUDIT_TYPE} | Source: ${SOURCE_TYPE}"
log "ðŸ“„ Rapport: ${REPORT_FILE}"

# Initialisation du rapport
case $OUTPUT_FORMAT in
    "markdown")
        cat > "$REPORT_FILE" << EOF
# ðŸ“‹ Rapport d'Audit : ${FEATURE_ID}

**Date**: $(date)
**Type**: ${AUDIT_TYPE}
**Source**: ${SOURCE_TYPE}
**Auditeur**: MÃ©thodologie Backend API (AutomatisÃ©)

---

## ðŸ“Š RÃ©sumÃ© ExÃ©cutif

**Status**: ðŸ”„ En cours...

EOF
        ;;
    "html")
        cat > "$REPORT_FILE" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>Audit Report: ${FEATURE_ID}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .score { font-size: 2em; font-weight: bold; }
        .excellent { color: #28a745; }
        .satisfactory { color: #ffc107; }
        .needs-improvement { color: #fd7e14; }
        .non-compliant { color: #dc3545; }
    </style>
</head>
<body>
    <h1>ðŸ“‹ Rapport d'Audit : ${FEATURE_ID}</h1>
    <p><strong>Date:</strong> $(date)</p>
    <p><strong>Type:</strong> ${AUDIT_TYPE}</p>
    <p><strong>Source:</strong> ${SOURCE_TYPE}</p>
    <div id="content">
        <p>ðŸ”„ GÃ©nÃ©ration en cours...</p>
    </div>
</body>
</html>
EOF
        ;;
    "json")
        cat > "$REPORT_FILE" << EOF
{
    "audit": {
        "feature_id": "${FEATURE_ID}",
        "type": "${AUDIT_TYPE}",
        "source": "${SOURCE_TYPE}",
        "date": "$(date -Iseconds)",
        "status": "in_progress",
        "scores": {},
        "findings": [],
        "recommendations": []
    }
}
EOF
        ;;
esac

# Phase 1: Tests automatisÃ©s (si activÃ©s)
if [[ "$RUN_TESTS" == "true" ]]; then
    log "ðŸ§ª Phase 1: ExÃ©cution des tests automatisÃ©s"

    cd "$PROJECT_ROOT"

    # Tests unitaires et fonctionnels
    if make test > /dev/null 2>&1; then
        success "Tests passants"
        TESTS_STATUS="âœ… PASS"
    else
        error "Tests Ã©chouent"
        TESTS_STATUS="âŒ FAIL"
    fi

    # Quality check
    if make quality-check > /dev/null 2>&1; then
        success "Quality check passant"
        QUALITY_STATUS="âœ… PASS"
    else
        error "Quality check Ã©choue"
        QUALITY_STATUS="âŒ FAIL"
    fi

    # Coverage
    if make coverage > /dev/null 2>&1; then
        COVERAGE_OUTPUT=$(make coverage 2>/dev/null | grep -oE '[0-9]+\.[0-9]+%' | tail -1)
        if [[ -n "$COVERAGE_OUTPUT" ]]; then
            COVERAGE_VALUE=${COVERAGE_OUTPUT%\%}
            if (( $(echo "$COVERAGE_VALUE > 80" | bc -l) )); then
                success "Coverage: $COVERAGE_OUTPUT"
                COVERAGE_STATUS="âœ… $COVERAGE_OUTPUT"
            else
                warning "Coverage insuffisant: $COVERAGE_OUTPUT"
                COVERAGE_STATUS="âš ï¸ $COVERAGE_OUTPUT"
            fi
        else
            warning "Coverage non dÃ©terminÃ©"
            COVERAGE_STATUS="â“ N/A"
        fi
    else
        warning "Coverage non disponible"
        COVERAGE_STATUS="â“ N/A"
    fi

    # Ajout au rapport
    cat >> "$REPORT_FILE" << EOF

## ðŸ§ª Tests AutomatisÃ©s

| Aspect | Status |
|--------|--------|
| Tests | ${TESTS_STATUS} |
| Quality Check | ${QUALITY_STATUS} |
| Coverage | ${COVERAGE_STATUS} |

EOF
fi

# Phase 2: Analyse spÃ©cifique selon le type d'audit
log "ðŸ” Phase 2: Analyse ${AUDIT_TYPE}"

case $AUDIT_TYPE in
    "full")
        log "Audit complet en cours..."
        # Ici on appellerait Claude Code via MCP ou API
        cat >> "$REPORT_FILE" << EOF

## ðŸ“Š Audit Complet

### Architecture (/10)
- ðŸ”„ Analyse en cours...

### QualitÃ© Code (/10)
- ðŸ”„ Analyse en cours...

### Tests (/10)
- ðŸ”„ Analyse en cours...

### Documentation (/10)
- ðŸ”„ Analyse en cours...

### Performance (/10)
- ðŸ”„ Analyse en cours...

### Production (/10)
- ðŸ”„ Analyse en cours...

EOF
        ;;
    "architecture")
        log "Audit architecture en cours..."
        cat >> "$REPORT_FILE" << EOF

## ðŸ—ï¸ Audit Architecture

### Service/Action Pattern
- ðŸ”„ VÃ©rification en cours...

### DTOs vs Arrays
- ðŸ”„ VÃ©rification en cours...

### Dependency Injection
- ðŸ”„ VÃ©rification en cours...

EOF
        ;;
    "tests")
        log "Audit tests en cours..."
        cat >> "$REPORT_FILE" << EOF

## ðŸ§ª Audit Tests DÃ©taillÃ©

### Coverage par Fichier
- ðŸ”„ Analyse en cours...

### QualitÃ© des Assertions
- ðŸ”„ Analyse en cours...

### Tests ManquÃ©s
- ðŸ”„ Identification en cours...

EOF
        ;;
    "performance")
        log "Audit performance en cours..."
        cat >> "$REPORT_FILE" << EOF

## âš¡ Audit Performance

### Response Times
- ðŸ”„ Mesure en cours...

### Database Queries
- ðŸ”„ Analyse N+1 en cours...

### Cache Strategy
- ðŸ”„ Ã‰valuation en cours...

EOF
        ;;
    "documentation")
        log "Audit documentation en cours..."
        cat >> "$REPORT_FILE" << EOF

## ðŸ“š Audit Documentation

### API Documentation
- ðŸ”„ VÃ©rification OpenAPI...

### Guides Utilisateur
- ðŸ”„ VÃ©rification prÃ©sence...

### Code Documentation
- ðŸ”„ Analyse PHPDoc...

EOF
        ;;
esac

# Phase 3: GÃ©nÃ©ration du prompt Claude Code
log "ðŸ¤– Phase 3: GÃ©nÃ©ration prompt Claude Code"

CLAUDE_PROMPT_FILE="${OUTPUT_DIR}/claude-audit-prompt-${FEATURE_ID//\//-}-${TIMESTAMP}.md"

cat > "$CLAUDE_PROMPT_FILE" << EOF
# ðŸ” Prompt d'Audit Automatique

Effectue un audit ${AUDIT_TYPE} de **${FEATURE_ID}** :

## Context
- **Source**: ${SOURCE_TYPE}
- **Type d'audit**: ${AUDIT_TYPE}
- **Rapport automatique**: ${REPORT_FILE}

## Instructions

$(case $SOURCE_TYPE in
    "jira")
        echo "1. RÃ©cupÃ¨re les dÃ©tails de ${FEATURE_ID} depuis Jira"
        echo "2. Liste tous les composants dÃ©veloppÃ©s pour cette story"
        ;;
    "namespace")
        echo "1. Analyse tous les fichiers dans ${FEATURE_ID}/"
        echo "2. Mappe l'architecture du module"
        ;;
    "commit")
        echo "1. Analyse les changements du commit ${FEATURE_ID}"
        echo "2. Ã‰value l'impact des modifications"
        ;;
    "pr")
        echo "1. Analyse la Pull Request #${FEATURE_ID}"
        echo "2. Ã‰value les changements proposÃ©s"
        ;;
esac)

3. Ã‰value selon la mÃ©thodologie backend-api-methodology.md
4. Utilise la checklist universelle comme rÃ©fÃ©rence
5. GÃ©nÃ¨re un scoring dÃ©taillÃ© pour chaque catÃ©gorie
6. Identifie les gaps avec prioritÃ© (critique/important/mineur)
7. Propose un plan d'amÃ©lioration concret

## Scoring Attendu

$(case $AUDIT_TYPE in
    "full")
        cat << SCORING
- Architecture (/10)
- QualitÃ© Code (/10)
- Tests (/10)
- Documentation (/10)
- Performance (/10)
- Production (/10)

**Score global pondÃ©rÃ©** : Architecture(25%) + QualitÃ©(20%) + Tests(25%) + Documentation(15%) + Performance(10%) + Production(5%)
SCORING
        ;;
    "architecture")
        echo "- Score Architecture dÃ©taillÃ© (/10) avec justifications"
        ;;
    "tests")
        echo "- Score Tests dÃ©taillÃ© (/10) avec recommandations"
        ;;
    "performance")
        echo "- Score Performance dÃ©taillÃ© (/10) avec optimisations"
        ;;
    "documentation")
        echo "- Score Documentation dÃ©taillÃ© (/10) avec gaps"
        ;;
esac)

## Format de Sortie
Remplace le contenu de \`${REPORT_FILE}\` par ton analyse complÃ¨te.

EOF

success "Prompt Claude Code gÃ©nÃ©rÃ©: ${CLAUDE_PROMPT_FILE}"

# Phase 4: Instructions finales
log "ðŸ“‹ Phase 4: Instructions finales"

cat >> "$REPORT_FILE" << EOF

---

## ðŸš€ Prochaines Ã‰tapes

1. **ExÃ©cuter l'audit complet** :
   \`\`\`
   Copie le contenu de ${CLAUDE_PROMPT_FILE} dans Claude Code
   \`\`\`

2. **Analyser les rÃ©sultats** :
   - Score global obtenu
   - Gaps critiques identifiÃ©s
   - Plan d'amÃ©lioration proposÃ©

3. **Actions correctives** :
   - Prioriser selon criticitÃ©
   - Planifier les amÃ©liorations
   - Re-auditer aprÃ¨s corrections

---

**Audit gÃ©nÃ©rÃ© automatiquement le $(date)**
**Script**: workflows/scripts/audit-feature.sh
EOF

# Affichage final
echo
success "ðŸŽ¯ Audit prÃ©parÃ© avec succÃ¨s !"
echo
echo "ðŸ“„ Rapport: ${REPORT_FILE}"
echo "ðŸ¤– Prompt Claude: ${CLAUDE_PROMPT_FILE}"
echo
echo "âž¡ï¸  Prochaines Ã©tapes :"
echo "   1. Copie le prompt dans Claude Code"
echo "   2. Claude analysera ${FEATURE_ID} selon la mÃ©thodologie"
echo "   3. Le rapport sera mis Ã  jour avec le scoring dÃ©taillÃ©"
echo
echo "ðŸ”— Commandes utiles :"
echo "   cat \"${CLAUDE_PROMPT_FILE}\" | pbcopy  # Copier le prompt"
echo "   open \"${REPORT_FILE}\"                # Ouvrir le rapport"
echo

# Optionnel: ouvrir automatiquement les fichiers
if command -v code &> /dev/null; then
    warning "Ouvrir les fichiers dans VS Code ? (y/n)"
    read -r -n 1 response
    if [[ $response =~ ^[Yy]$ ]]; then
        code "$CLAUDE_PROMPT_FILE" "$REPORT_FILE"
    fi
fi

exit 0